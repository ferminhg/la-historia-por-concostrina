{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription embedders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Habilitar la extensi칩n de vectores\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "-- Crear tabla para almacenar embeddings\n",
    "CREATE TABLE podcast_embeddings (\n",
    "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
    "    content TEXT NOT NULL,\n",
    "    metadata JSONB,\n",
    "    embedding vector(1536), -- text-embedding-3-small usa 1536 dimensiones\n",
    "    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n",
    ");\n",
    "\n",
    "-- Funci칩n corregida que usa la tabla podcast_embeddings\n",
    "create or replace function match_documents (\n",
    "  query_embedding vector (1536),\n",
    "  filter jsonb default '{}',\n",
    "  match_count int default 5\n",
    ") returns table (\n",
    "  id uuid,\n",
    "  content text,\n",
    "  metadata jsonb,\n",
    "  similarity float\n",
    ") language plpgsql as $$\n",
    "#variable_conflict use_column\n",
    "begin\n",
    "  return query\n",
    "  select\n",
    "    podcast_embeddings.id,\n",
    "    podcast_embeddings.content,\n",
    "    podcast_embeddings.metadata,\n",
    "    1 - (podcast_embeddings.embedding <=> query_embedding) as similarity\n",
    "  from podcast_embeddings\n",
    "  where podcast_embeddings.metadata @> filter\n",
    "  order by podcast_embeddings.embedding <=> query_embedding\n",
    "  limit match_count;\n",
    "end;\n",
    "$$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticChunker:\n",
    "    \"\"\"Chunker sem치ntico especializado para transcripciones de podcast\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 1500, chunk_overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"],\n",
    "            keep_separator=True\n",
    "        )\n",
    "    \n",
    "    def detect_topic_boundaries(self, text: str) -> List[int]:\n",
    "        \"\"\"Detecta l칤mites de temas basado en patrones comunes en podcasts\"\"\"\n",
    "        boundaries = [0]\n",
    "        \n",
    "        # Patrones que indican cambio de tema\n",
    "        patterns = [\n",
    "            r'\\b(?:ahora|bueno|entonces|por otro lado|cambiando de tema|hablando de)\\b',\n",
    "            r'\\b(?:siguiente pregunta|otra cosa|pasemos a|vamos a hablar)\\b',\n",
    "            r'\\n\\n',  # P치rrafos nuevos\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = list(re.finditer(pattern, text, re.IGNORECASE))\n",
    "            for match in matches:\n",
    "                boundaries.append(match.start())\n",
    "        \n",
    "        # Ordenar y eliminar duplicados\n",
    "        boundaries = sorted(list(set(boundaries)))\n",
    "        boundaries.append(len(text))\n",
    "        \n",
    "        return boundaries\n",
    "    \n",
    "    def chunk_transcript(self, text: str, episode_metadata: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Divide la transcripci칩n en chunks sem치nticamente coherentes\"\"\"\n",
    "        boundaries = self.detect_topic_boundaries(text)\n",
    "        chunks = []\n",
    "        \n",
    "        # Estimar duraci칩n total (asumiendo ~150 palabras por minuto)\n",
    "        total_words = len(text.split())\n",
    "        estimated_duration_minutes = total_words / 150\n",
    "        \n",
    "        for i in range(len(boundaries) - 1):\n",
    "            start_pos = boundaries[i]\n",
    "            end_pos = boundaries[i + 1]\n",
    "            \n",
    "            segment = text[start_pos:end_pos].strip()\n",
    "            \n",
    "            if len(segment) < 100:  # Skip chunks muy peque침os\n",
    "                continue\n",
    "            \n",
    "            # Si el segmento es muy largo, usar text_splitter tradicional\n",
    "            if len(segment) > self.chunk_size:\n",
    "                sub_chunks = self.text_splitter.split_text(segment)\n",
    "                \n",
    "                for j, sub_chunk in enumerate(sub_chunks):\n",
    "                    # Calcular timestamp estimado\n",
    "                    progress = (start_pos + j * len(sub_chunk)) / len(text)\n",
    "                    estimated_timestamp = progress * estimated_duration_minutes\n",
    "                    \n",
    "                    chunk_metadata = {\n",
    "                        **episode_metadata,\n",
    "                        \"chunk_index\": len(chunks),\n",
    "                        \"estimated_timestamp_minutes\": round(estimated_timestamp, 2),\n",
    "                        \"chunk_type\": \"semantic_sub\",\n",
    "                        \"word_count\": len(sub_chunk.split())\n",
    "                    }\n",
    "                    \n",
    "                    chunks.append({\n",
    "                        \"content\": sub_chunk,\n",
    "                        \"metadata\": chunk_metadata\n",
    "                    })\n",
    "            else:\n",
    "                # Calcular timestamp estimado\n",
    "                progress = start_pos / len(text)\n",
    "                estimated_timestamp = progress * estimated_duration_minutes\n",
    "                \n",
    "                chunk_metadata = {\n",
    "                    **episode_metadata,\n",
    "                    \"chunk_index\": len(chunks),\n",
    "                    \"estimated_timestamp_minutes\": round(estimated_timestamp, 2),\n",
    "                    \"chunk_type\": \"semantic\",\n",
    "                    \"word_count\": len(segment.split())\n",
    "                }\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"content\": segment,\n",
    "                    \"metadata\": chunk_metadata\n",
    "                })\n",
    "        \n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastIndexer:\n",
    "    \"\"\"Sistema principal de indexaci칩n para transcripciones de podcast\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # Configurar Supabase\n",
    "        supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "        supabase_key = os.getenv(\"SUPABASE_KEY\")\n",
    "        \n",
    "        if not supabase_url or not supabase_key:\n",
    "            raise ValueError(\"SUPABASE_URL y SUPABASE_KEY deben estar configurados\")\n",
    "        \n",
    "        self.supabase_client: Client = create_client(supabase_url, supabase_key)\n",
    "        self.vector_store = SupabaseVectorStore(\n",
    "            client=self.supabase_client,\n",
    "            embedding=self.embeddings,\n",
    "            table_name=\"podcast_embeddings\",\n",
    "            query_name=\"match_documents\"\n",
    "        )\n",
    "        self.chunker = SemanticChunker()\n",
    "    \n",
    "    def extract_episode_metadata(self, file_path: Path) -> Dict[str, Any]:\n",
    "        \n",
    "        filename = file_path.stem\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error leyendo JSON {file_path}: {str(e)}\")\n",
    "            data = {}\n",
    "        \n",
    "        episode_id = data.get(\"episode_id\", filename)\n",
    "        title = data.get(\"title\", episode_id)\n",
    "        duration = data.get(\"duration\", 0)\n",
    "        language = data.get(\"language\", \"unknown\")\n",
    "        audio_file_path = data.get(\"file_path\", \"\")\n",
    "        \n",
    "        return {\n",
    "            \"episode_id\": episode_id,\n",
    "            \"title\": title,\n",
    "            \"filename\": filename,\n",
    "            \"source_file\": str(file_path),\n",
    "            \"duration\": duration,\n",
    "            \"language\": language,\n",
    "            \"file_path\": audio_file_path\n",
    "        }\n",
    "\n",
    "    \n",
    "    def process_transcript_file(self, file_path: Path) -> List[Dict[str, Any]]:\n",
    "        logger.info(f\"Procesando: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            episode_metadata = self.extract_episode_metadata(file_path)\n",
    "            chunks = self.chunker.chunk_transcript(content, episode_metadata)\n",
    "            \n",
    "            logger.info(f\"Generados {len(chunks)} chunks para {file_path.name}\")\n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error procesando {file_path}: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def index_transcripts(self, transcripts_dir: str = \"transcripciones\"):\n",
    "        transcripts_path = Path(transcripts_dir)\n",
    "        \n",
    "        if not transcripts_path.exists():\n",
    "            raise FileNotFoundError(f\"Directorio {transcripts_dir} no encontrado\")\n",
    "        \n",
    "        transcript_files = list(transcripts_path.glob(\"*.json\"))\n",
    " \n",
    "        \n",
    "        # Seleccionar solo 2 archivos aleatorios\n",
    "        # transcript_files = random.sample(transcript_files, min(2, len(transcript_files)))\n",
    "        \n",
    "        if not transcript_files:\n",
    "            logger.warning(f\"No se encontraron archivos .txt en {transcripts_dir}\")\n",
    "            return\n",
    "        \n",
    "        logger.info(f\"Encontrados {len(transcript_files)} archivos de transcripci칩n\")\n",
    "        \n",
    "        all_chunks = []\n",
    "        \n",
    "        # Procesar cada archivo\n",
    "        for file_path in transcript_files:\n",
    "            chunks = self.process_transcript_file(file_path)\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        if not all_chunks:\n",
    "            logger.warning(\"No se generaron chunks para indexar\")\n",
    "            return\n",
    "        \n",
    "        logger.info(f\"Total de chunks a indexar: {len(all_chunks)}\")\n",
    "        \n",
    "        texts = [chunk[\"content\"] for chunk in all_chunks]\n",
    "        metadatas = [chunk[\"metadata\"] for chunk in all_chunks]\n",
    "        \n",
    "        batch_size = 50\n",
    "        total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            batch_metadatas = metadatas[i:i + batch_size]\n",
    "            current_batch = (i // batch_size) + 1\n",
    "            \n",
    "            try:\n",
    "                self.vector_store.add_texts(\n",
    "                    texts=batch_texts,\n",
    "                    metadatas=batch_metadatas\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Batch {current_batch}/{total_batches} indexado exitosamente\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error indexando batch {current_batch}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(\"Indexaci칩n completada!\")\n",
    "    \n",
    "    def search_episodes(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            logger.info(f\"Buscando: '{query}' con k={k}\")\n",
    "            \n",
    "            # Verificar conexi칩n a Supabase\n",
    "            logger.info(\"Verificando conexi칩n a Supabase...\")\n",
    "            \n",
    "            # Intentar b칰squeda\n",
    "            docs = self.vector_store.similarity_search(query=query, k=k)\n",
    "            logger.info(f\"B칰squeda exitosa, encontrados {len(docs)} documentos\")\n",
    "            \n",
    "            results = []\n",
    "            for doc in docs:\n",
    "                result = {\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                }\n",
    "                results.append(result)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            logger.error(f\"Error en b칰squeda: {str(e)}\")\n",
    "            logger.error(f\"Tipo de error: {type(e).__name__}\")\n",
    "            logger.error(f\"Traceback completo:\\n{traceback.format_exc()}\")\n",
    "            \n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten cuidad con ejecutar de nuevo. 游뚿\n",
    "indexer = PodcastIndexer()\n",
    "# indexer.index_transcripts(\"../data/transcriptions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:41:31,684 - INFO - Buscando: 'Iglesia catolica' con k=5\n",
      "2025-07-06 19:41:31,685 - INFO - Verificando conexi칩n a Supabase...\n",
      "2025-07-06 19:41:32,292 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-07-06 19:41:32,663 - INFO - HTTP Request: POST https://zdanxslxyfhuvwqczyig.supabase.co/rest/v1/rpc/match_documents?limit=5 \"HTTP/2 200 OK\"\n",
      "2025-07-06 19:41:32,674 - INFO - B칰squeda exitosa, encontrados 5 documentos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'ahora viene la extravagancia Ya sabemos todos que la secta cat칩lica tiene por norma trapichear con huesos de muertos para ponerlos debajo de sus altares Durante la inauguraci칩n de esta sede del Opus en el CSIC buscaron los huesos m치s oportunos, dado que hab칤an declarado patr칩n espiritual al tal Isidoro de Sevilla Oye,',\n",
       "  'metadata': {'title': '20240520_190000',\n",
       "   'duration': 925,\n",
       "   'filename': '20240520_190000',\n",
       "   'language': 'es',\n",
       "   'file_path': '/Users/seedtag/projects/personal/la-historia-por-concostrina/podcast_crawler/app/../../audios/2024_05_20_19.mp3',\n",
       "   'chunk_type': 'semantic',\n",
       "   'episode_id': '20240520_190000',\n",
       "   'word_count': 53,\n",
       "   'chunk_index': 12,\n",
       "   'source_file': '../data/transcriptions/20240520_190000.json',\n",
       "   'estimated_timestamp_minutes': 10.06}},\n",
       " {'content': 'bueno, hay que recordar que la rep칰blica no tuvo oportunidad de desarrollar plenamente esa constituci칩n aprobada en el 31, ni de secularizar la ense침anza, porque lo impidi칩 un golpe de estado. O sea, todo eso que estaba previsto de hacer, ta ta ta, pum, de repente se fren칩 de golpe. Hab칤a un buen plan, pero que no se pudo desarrollar nada. Es que no se pudo, no se pudo. Era una constituci칩n muy progresista, pero se fren칩 todo. Pero por lo de siempre, la alianza del trono, el altar y el fascismo, esa alianza lo impidi칩. En este pa칤s no hay forma de sacudirse de encima a una iglesia cat칩lica que adem치s de no contribuir estorba, que es lo peor. No paga y exige. Se salta todos los mandamientos, pero exigen que los cumplan sus clientes. Y est치n tan mal acostumbrados y han abusado tanto a lo largo de los siglos que a칰n hoy se sienten con derecho a todo, porque hasta los gobiernos que nos quieren hacer creer que son progresistas siguen regando a una jerarqu칤a eclesi치stica de dinero p칰blico cuando nos falta dinero para la investigaci칩n. Ya se escuch칩 esta tarde a Isa칤as, cuando habl치bamos de ese convento de Sevilla, de donde van a...',\n",
       "  'metadata': {'title': '20240206_193433',\n",
       "   'duration': 857,\n",
       "   'filename': '20240206_193433',\n",
       "   'language': 'es',\n",
       "   'file_path': '/Users/seedtag/projects/personal/la-historia-por-concostrina/podcast_crawler/app/../../audios/2024_02_06_19.mp3',\n",
       "   'chunk_type': 'semantic',\n",
       "   'episode_id': '20240206_193433',\n",
       "   'word_count': 206,\n",
       "   'chunk_index': 11,\n",
       "   'source_file': '../data/transcriptions/20240206_193433.json',\n",
       "   'estimated_timestamp_minutes': 10.93}},\n",
       " {'content': '. Por aquel pueblo pas칩 cuatro a침os despu칠s dando la turra con el evangelio el franciscano Fray Toribio que se enter칩 de que all칤 estaba enterrado el celebrado Cuauht칠moc y decidi칩 construir sobre su tumba la iglesia de Nuestra Se침ora de la Asunci칩n Eso es tener punter칤a S칤, claro, a falta de un santo te pillan a un azteca y dices con tal de construir algo yo un gamus칤n a un azteca da lo mismo como si fuera San Pedro el caso es que este hombre tiene all칤 una iglesia Yo esto me lo creo porque los curas cuando van a abrir nueva l칤nea de negocio inauguran nueva sede de la multinacional con la excusa de cualquier muerto, les da igual y si esto fuera cierto hay que ver la idiotez, si Cuauht칠moc el 칰ltimo emperador mexica asesinado por los cat칩licos estuviera enterrado bajo el altar mayor de una sucursal cat칩lica se quejan los mexicanos de los invasores espa침oles con raz칩n, yo lo entiendo, pero la peor consecuencia visto',\n",
       "  'metadata': {'title': '20240228_191812',\n",
       "   'duration': 1050,\n",
       "   'filename': '20240228_191812',\n",
       "   'language': 'es',\n",
       "   'file_path': '/Users/seedtag/projects/personal/la-historia-por-concostrina/podcast_crawler/app/../../audios/2024_02_28_19.mp3',\n",
       "   'chunk_type': 'semantic_sub',\n",
       "   'episode_id': '20240228_191812',\n",
       "   'word_count': 169,\n",
       "   'chunk_index': 13,\n",
       "   'source_file': '../data/transcriptions/20240228_191812.json',\n",
       "   'estimated_timestamp_minutes': 11.2}},\n",
       " {'content': 'bueno, ya han hecho cuatro apartamentos tur칤sticos dentro del convento, y Isa칤as ha comentado, oye, pues por ah칤 podr칤a abrirse una v칤a para que con todos los inmuebles que tiene la iglesia alg칰n d칤a pudiera autofinanciarse, a lo que se comprometieron hace un mont칩n de a침os. Oye, igual por ah칤, yo no creo, pero igual por ah칤 suena la flauta. Nada, ni suena la flauta porque estos no tocan la flauta, sino es para adentro. Perdimos el paso del progreso en el 19 y todo fue a peor, empeor칩 much칤simo a partir de 1851, cuando el papa P칤o Nono... El pastelito. Pues cuando P칤o Nono y la reina Isabel II, esa de la que el propio papa dec칤a, e putana ma p칤a, es una puta pero es devota. S칤, eso dec칤a, le dieron un premio y alguien le dijo, pero si Isabel II es una puta, le dijo un cardenal y dijo, e putana ma p칤a. Pues desde que estord칩, os digo, firmaron el concordato que reconoc칤a el derecho de la iglesia a inspeccionar la ense침anza tanto p칰blica como privada. Eso es de 1851 y eso que no hemos contado que a칰n faltaba por desarrollar la ley para respaldar los puntos cuarto y quinto del art칤culo 26 de la Constituci칩n del 31, que prohib칤a a todas las 칩rdenes religiosas ejercer la industria, el comercio y la ense침anza y estaban obligadas a someterse a todas las leyes tributarias del pa칤s. Esa era la buena constituci칩n',\n",
       "  'metadata': {'title': '20240206_193433',\n",
       "   'duration': 857,\n",
       "   'filename': '20240206_193433',\n",
       "   'language': 'es',\n",
       "   'file_path': '/Users/seedtag/projects/personal/la-historia-por-concostrina/podcast_crawler/app/../../audios/2024_02_06_19.mp3',\n",
       "   'chunk_type': 'semantic_sub',\n",
       "   'episode_id': '20240206_193433',\n",
       "   'word_count': 244,\n",
       "   'chunk_index': 12,\n",
       "   'source_file': '../data/transcriptions/20240206_193433.json',\n",
       "   'estimated_timestamp_minutes': 12.25}},\n",
       " {'content': '. Pero claro, hab칤a excepciones muy razonables a las que nadie prestaba atenci칩n, porque aqu칤 lo que se trataba era de montar el pollo y dar la bronca. Esa es una de las excepciones. Si todos los padres y el profesor estaban de acuerdo, el crucifijo pod칤a quedarse en el aula. Todos estaban todos de acuerdo. Y si los padres quisieran que sus hijos recibieran clases de religi칩n, pues se respetar칤a. Pero claro, ten칤an que estar todos de acuerdo. Como un extraescolar, parece. Claro. Eso era, pues eso, al margen de las materias importantes y serias. Ustedes quieren esto, pues se puede mantener, pero tienen que estar todos de acuerdo. Pero el caso es que a partir de aqu칤 los curas montaron sus performance a lo largo y ancho del territorio la ICO Nacional. 쮺칩mo? 쮺on qu칠? 쯇rocesiones? 쯄anifestaciones? 쮼ncierros? 쮹urgos de hambre? De todo un poco. Y visto desde la distancia, pues algunas eran aut칠nticas payasadas, aunque no ten칤an maldita gracia. Los curas iban organizando protestas o procesiones por pueblos y ciudades. Cada d칤a la liaban en un lugar. Ejemplos pr치cticos. El cura de un pueblo de Granada que se llama Aled칤n mont칩 una procesi칩n con una asociaci칩n agraria de cat칩licos, una procesi칩n aparentemente piadosa, a la que arrastraron a los vecinos que no se enteran que cuando un cura te movilices para defender lo suyo. Defiende su buche, su negocio, sus ingresos. No defiende las necesidades del pueblo. Pues aquella procesi칩n se volvi칩 violenta',\n",
       "  'metadata': {'title': '20240206_193433',\n",
       "   'duration': 857,\n",
       "   'filename': '20240206_193433',\n",
       "   'language': 'es',\n",
       "   'file_path': '/Users/seedtag/projects/personal/la-historia-por-concostrina/podcast_crawler/app/../../audios/2024_02_06_19.mp3',\n",
       "   'chunk_type': 'semantic_sub',\n",
       "   'episode_id': '20240206_193433',\n",
       "   'word_count': 246,\n",
       "   'chunk_index': 6,\n",
       "   'source_file': '../data/transcriptions/20240206_193433.json',\n",
       "   'estimated_timestamp_minutes': 4.96}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = PodcastIndexer()\n",
    "indexer.search_episodes(\"Iglesia catolica\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la-historia-por-concostrina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
