{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEPRECATED by podcast_crawler\n",
        "\n",
        "This notebook is used to scrap the episodes of the podcast La Historia Por Concostrina.\n",
        "\n",
        "The RSS feed is available at https://fapi-top.prisasd.com/podcast/playser/todo_concostrina/itunestfp/podcast.xml\n",
        "\n",
        "The episodes are in the <item> tag.\n",
        "\n",
        "The title is in the <title> tag.\n",
        "\n",
        "The description is in the <description> tag.\n",
        "\n",
        "The pubDate is in the <pubDate> tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descargar los XMLs y guardarlos localmente\n",
        "import requests\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# URLs de los RSS\n",
        "rss_urls = [\n",
        "    'https://fapi-top.prisasd.com/podcast/playser/cualquier_tiempo_pasado_fue_anterior/itunestfp/podcast.xml',\n",
        "    'https://fapi-top.prisasd.com/podcast/playser/todo_concostrina/itunestfp/podcast.xml'\n",
        "]\n",
        "\n",
        "# Crear carpeta data si no existe\n",
        "os.makedirs('../data', exist_ok=True)\n",
        "\n",
        "# Descargar cada XML\n",
        "for i, rss_url in enumerate(rss_urls):\n",
        "    filename = f'feed_{i+1}.xml'\n",
        "    filepath = os.path.join('../data', filename)\n",
        "    \n",
        "    print(f\"Descargando {rss_url} -> {filename}\")\n",
        "    response = requests.get(rss_url)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "    \n",
        "    print(f\"Guardado en {filepath}\")\n",
        "\n",
        "print(\"XMLs descargados correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_pubdate(pubdate):\n",
        "    try:\n",
        "        dt = datetime.strptime(pubdate[:25], '%a, %d %b %Y %H:%M:%S')\n",
        "        return dt.strftime('%Y_%m_%d_%H')\n",
        "    except Exception as e:\n",
        "        print(f'Error formateando fecha: {pubdate} -> {e}')\n",
        "        return pubdate.replace(' ', '_').replace(':', '_')\n",
        "\n",
        "def clean_html(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    return re.sub(cleanr, '', raw_html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Archivos XML locales\n",
        "xml_files = [\n",
        "    '../data/feed_1.xml',\n",
        "    '../data/feed_2.xml'\n",
        "]\n",
        "\n",
        "episodes = []\n",
        "\n",
        "for i, xml_file in enumerate(xml_files):\n",
        "    print(f\"Procesando archivo {i+1}: {xml_file}\")\n",
        "    \n",
        "    with open(xml_file, 'r', encoding='utf-8') as f:\n",
        "        xml_content = f.read()\n",
        "    \n",
        "    root = ET.fromstring(xml_content)\n",
        "    feed_episodes = 0\n",
        "    \n",
        "    for item in root.findall('.//item'):\n",
        "        title = item.find('title').text if item.find('title') is not None else ''\n",
        "        description = item.find('description').text if item.find('description') is not None else ''\n",
        "        pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ''\n",
        "        enclosure = item.find('enclosure')\n",
        "        \n",
        "        link = enclosure.attrib['url'] if enclosure is not None and 'url' in enclosure.attrib else ''\n",
        "\n",
        "        description_clean = clean_html(description)\n",
        "        episodes.append({\n",
        "            'title': title,\n",
        "            'description': description_clean,\n",
        "            'pubDate': pub_date,\n",
        "            'link': link,\n",
        "            'audioFileName': format_pubdate(pub_date) + '.mp3'\n",
        "        })\n",
        "        feed_episodes += 1\n",
        "    \n",
        "    print(f\"Feed {i+1} contribuyó con {feed_episodes} episodios\")\n",
        "\n",
        "print(f\"Se encontraron {len(episodes)} episodios en total\")\n",
        "\n",
        "# Guardar en JSON\n",
        "with open('../data/episodes.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(episodes, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Episodios guardados en ../data/episodes.json\")\n",
        "\n",
        "# Mostrar los primeros 3 episodios como ejemplo\n",
        "print(\"\\nPrimeros 3 episodios:\")\n",
        "for i, episode in enumerate(episodes[:3]):\n",
        "    print(f\"\\n{i+1}. {episode['title']}\")\n",
        "    print(f\"   Fecha: {episode['pubDate']}\")\n",
        "    print(f\"   Descripción: {episode['description'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Cargar los episodios\n",
        "with open('../data/episodes.json', 'r', encoding='utf-8') as f:\n",
        "    episodes = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "for ep in episodes:\n",
        "    url = ep.get('link', '')\n",
        "    pubdate = ep.get('pubDate', '')\n",
        "    if not url:\n",
        "        continue\n",
        "    filename = format_pubdate(pubdate) + '.mp3'\n",
        "    filepath = os.path.join('../audios', filename)\n",
        "    if os.path.exists(filepath):\n",
        "        print(f'Saltando {filename}, ya existe.')\n",
        "        continue\n",
        "    try:\n",
        "        print(f'Descargando {filename}...')\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(filepath, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "        print(f'Guardado en {filepath}')\n",
        "    except Exception as e:\n",
        "        print(f'Error descargando {url}: {e}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "la-historia-por-concostrina",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
